---
marp: true
paginate: true
---
<style>
:root {
  font-family: 'Noto Sans JP';    
  color: #444;
}
:root ol {
  list-style-type: decimal;
}
:root h1, h2, h3, h4, h5, h6{
  font-family: 'Noto Sans JP Black';
  color: #2277cc;
}
pre, code {
  font-family: 'Roboto mono', 'Noto Sans JP';
  line-height: 1.5;
}
</style>

# Artificial Intelligence and Creation<br>Critique: Generated Video “Hallucination – Bad Trip”<br>AI and Music Production

Tokyo University of the Arts Arts and Media Center
Atsushi Tadokoro

---

## Today's topics

First, we'll critique your generated videos for “Hallucination – Bad Trip.” Then we will delve into AI-assisted music creation. We'll introduce technologies, examples, and works for music-making with generative AI. Finally, in practice, we will challenge music generation with Suno AI.

---


## Critique: Generated Video “Hallucination – Bad Trip”

Please submit via Google Classroom!

---

## AI and Music Production

---

### Creating music with Generative AI

#### [Nao Tokui - AI DJ Project (2016)](https://qosmo.jp/art/ai-dj-human-dj-b2b)

![height:480](https://qosmo.jp/_next/image?url=https%3A%2F%2Fimages.ctfassets.net%2Fjhi4pj6pvhnp%2F3eG75oywwM54TqW8xABVqI%2Fc6b56fcb9f9d0d5a61ff8af648ab5b52%2FIMG_0043.JPG%3Ffm%3Dwebp%26w%3D1920%26h%3D1080%26fit%3Dpad%26bg%3Drgb%3A000000&w=2048&q=75)

---

Nao Tokui's AI DJ Project is a live performance in which an AI and a human DJ alternately play tracks in a back-to-back format. The AI uses deep learning to select and mix tracks. This project explores new musical creativity through dialogue between AI and humans and has attracted attention in Japan and abroad.

---

#### [Holly Herndon & Jlin (feat. Spawn) - Godmother (2018)](https://youtu.be/sc9OjL6Mjqo?si=SZOm9GhS2d6zwpZl)

![height:480](https://i.ytimg.com/vi/sc9OjL6Mjqo/maxresdefault.jpg)

---

Released in 2018, “Godmother” is a collaboration by Holly Herndon and Jlin, featuring an AI named Spawn. Spawn, developed by Herndon and Mat Dryhurst, learned Jlin’s musical style and attempted to reproduce it using Herndon’s voice. The project drew attention as an exploration of how AI can coexist with human creativity to produce new musical expressions.

Reference: [Holly Herndon and Jlin’s “Godmother” features an A.I. named Spawn](https://www.thefader.com/2018/12/04/holly-herndon-jlin-godmother-spawn-ai-music-video)

---

### [Brian Eno – Reflection](https://www.youtube.com/watch?v=fSofXKGpenQ)

![height:480](https://i.ytimg.com/vi/fSofXKGpenQ/maxresdefault.jpg)

---

Brian Eno’s album ‘Reflection’ was created using generative music methods. He collected multiple sounds and phrases, set specific rules, and ran a system designed to generate ever-changing music. This process resembles AI’s automated generative approach; Eno’s role shifted from composer to programmer-observer, enjoying the process of music generation.

Reference: Brian Eno's self-reflection in ‘Reflection’

---

#### [The Beatles - Now And Then (2023)](https://youtu.be/AW55J2zE3N4?si=1A18nDsyifkysFAJ)

![height:480](https://i.ytimg.com/vi/Opxhh9Oh3rg/hq720.jpg?sqp=-oaymwEhCK4FEIIDSFryq4qpAxMIARUAAAAAGAElAADIQj0AgKJD&rs=AOn4CLDToUSNIbJe9wSRyCjtebMv3j-HuQ)

---

“Now And Then” is a Beatles track completed using AI based on a home-recorded demo tape by John Lennon in the late 1970s. Where older technology couldn’t separate piano and vocals, modern AI enabled a clean extraction of Lennon’s voice. Paul McCartney and Ringo Starr added new performances, and the song was released in 2023 as the final Beatles track.

Reference: [How the Beatles’ final new song “Now and Then” was made](https://www.gizmodo.jp/2023/11/listen-to-ai-john-lennon-in-the-beatles-final-new-son.html)

---

#### Reference: [AI and Music Making: The State of Play](https://www.ableton.com/ja/blog/ai-and-music-making-the-state-of-play/)

![height:480](https://cdn-resources.ableton.com/resources/filer_thumbnails/images/blog/ai-music/01_ai_in_music_making_part_1.jpg__800x1667_q85_subsampling-2.jpg)

---

Analyzes the impact of AI on music production. AI enables tasks like stem separation and vocal deepfakes, expanding possibilities in traditional production workflows. However, AI also raises discussions about creativity, ownership, and authenticity. The article explores whether AI threatens or augments human creativity and looks toward the future of music creation.


---

### Generative AI as a music creation tool

#### [Google + DeepMind - NSynth Super (2017)](https://nsynthsuper.withgoogle.com/)

![height:480](https://storage.googleapis.com/gweb-uniblog-publish-prod/images/01._NSynth-Super-Instrument_2120x888.width-1300.jpg)

---

NSynth Super is a synthesizer co-developed by Google’s Magenta project and DeepMind. It uses the "NSynth" machine learning algorithm to generate new timbres by combining existing instrument sounds. NSynth uses a WaveNet-style autoencoder trained on a dataset of about 300,000 instrument samples. NSynth Super features a touchscreen hardware interface where users can pick four sources and intuitively morph new timbres. The project is open source on GitHub and can be self-built. It broadened possibilities for AI-assisted sound design and offered an innovative tool for artists and creators.


---

#### [Neutone (Qosmo, Nao Tokui) - Neutone Morpho (2024)](https://neutone.ai/morpho)

![height:480](https://i.ytimg.com/vi/CI79qnstFN0/maxresdefault.jpg)

---

Neutone Morpho is a machine learning-based audio plugin developed by Neutone Inc. It instantly transforms input audio into different sounds—e.g. converting a voice into violin or djembe in real time. Aimed at augmenting creativity, it uses AI to enable new expressions in music production. The project is led by Nao Tokui, head of Qosmo and founder of Neutone. With Morpho’s release, AI-powered production methods have widened in the field, marking a key step for AI in music.

---

#### [Jacob Collier + Google, MusicFX DJ | Google Lab Sessions (2024)](https://blog.google/technology/ai/jacob-collier-labs-sessions/)

![height:480](https://storage.googleapis.com/gweb-uniblog-publish-prod/images/Jacob_Collier_2096x1182_02_1.width-1300.jpg)

---

In 2024, Grammy winner Jacob Collier collaborated with Google DeepMind and Google Labs to develop "MusicFX DJ," a music generation tool. Users can combine prompts like instruments, genres, and mood to generate and improvise music in real time with AI. Collier contributed to a design prioritizing intuitive operation and creativity, for both beginners and pros. Generated music can be shared and remixed, facilitating collaborative creation.

---

## Try music generation AI!

---

## Google MusicFX DJ

![height:480](https://i0.wp.com/cdn.mos.cms.futurecdn.net/U6wqxT5vnwvpEqZ9qC5yQN.jpg?ssl=1)

---

Google’s "MusicFX DJ" is an AI-powered music generation tool. Users specify genre, instruments, and mood in text to generate and manipulate music in real time.

With an intuitive interface, anyone can create original tracks without specialized knowledge. Generated music can be downloaded and shared, fostering creative collaboration.

- [https://aitestkitchen.withgoogle.com/tools/music-fx-dj](https://aitestkitchen.withgoogle.com/tools/music-fx-dj)

---

### Suno AI


![height:200](https://aianimation.com/wp-content/uploads/2024/01/Suno-Logo.jpg)

- [https://suno.com/](https://suno.com/)

Suno AI automatically generates music based on text input. It can produce songs with vocals, instruments, and backing tracks according to provided lyrics or ideas. It supports Japanese, making it easy to create songs with Japanese lyrics. The free plan allows up to 10 songs per day; commercial use requires a paid plan. A May 2024 update enabled tracks up to 4 minutes, significantly enhancing capability.

---

Main ways to use Suno AI

- Enter a text prompt: specify theme and mood; the AI composes accordingly
- Input lyrics: provide your lyrics for melody and accompaniment generation
- Choose a genre: pop, jazz, classical, etc. for stylistic control
- Use Custom mode: set tempo, instrumentation, vocal style, and length
- Instrumental option: generate without vocals
- Extend: lengthen generated tracks further

---

### Reference: Neutone Morpho

![height:200](https://neutone.ai/morpho/morpho-logo.svg)

[https://neutone.ai/morpho](https://neutone.ai/morpho)

---

Neutone Morpho is a real-time tone-morphing plugin leveraging cutting-edge ML. It transforms input audio into different timbres and styles—for example, turning a human voice into a violin, or everyday sounds into a drum kit. Using pre-trained AI models, it performs real-time conversion. The free version offers four models; paid tiers add more models and custom training. Works on Mac (Apple Silicon native) and Windows, supporting AU/VST3 formats for DAWs.

---

Main features of Neutone Morpho

- Real-time tone morphing: instantly transform input audio into new timbres
- Diverse AI models: drums, voice, choir, violin, effects, and more
- Custom model training: build your own models from your datasets
- Macro and micro control views: high-level control via four knobs; fine parameter tuning in detail view
- Pre/post-processing: pitch shift, feedback delay, compressor, noise gate, limiter, etc.

---

## Practice: Add music to your AI-generated video

- Add music to your “Hallucination – Bad Trip” video
  - First, attempt music generation that matches the visuals
  - Generate with [Suno AI](https://suno.com/)
  - Generate with [Google MusicFX](https://aitestkitchen.withgoogle.com/tools/music-fx-dj)
  - Produce with [Neutone Morph](https://neutone.ai/morpho)
  … etc.
- If possible, add audio in a video editor
  - DaVinci Resolve
  - Adobe Premiere
  - Apple Final Cut Pro
  … etc.

---

## Practice: Add music with Suno AI

- Add music to your “Hallucination - Bad Trip” video
- First, attempt music generation that matches the visuals
- If possible, add audio in a video editor
  - DaVinci Resolve
  - Adobe Premiere
  - Apple Final Cut Pro
  ... etc.
